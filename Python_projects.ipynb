{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "In particular, import numpy, matplotlib and sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics, tree, ensemble\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Plots PhD thesis \n",
    "Plot of the analysis output (satisfaction probability) over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data=np.loadtxt(\"./Output_M1.txt\")\n",
    "X=data[:, 0][0:200]\n",
    "Y2=data[:, 2][0:200]\n",
    "\n",
    "#plot data\n",
    "plt.plot(X,Y2,linewidth=0.75,color='crimson',label = '$p^*_{M_1}$')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Estimated satisfaction probability')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple project\n",
    "Temperature conversion: Celsius to Fahrenheit and Fahrenheit to Celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Welcome To Temperature Converter!')\n",
    "\n",
    "#input value and scale\n",
    "temp = None\n",
    "while temp is None:\n",
    "    try:\n",
    "        temp = float(input(\"Enter the temperature: \"))\n",
    "    except ValueError:\n",
    "        print (\"Please enter an appropriate temperature value!\")\n",
    "\n",
    "scale=input(\"Enter the scale (C/F): \")\n",
    "\n",
    "a = '\\u00b0'\n",
    "\n",
    "#if loop for conversion\n",
    "if (scale == \"C\"):\n",
    "    t = temp * 1.8 + 32\n",
    "    print(\"The temperature is\", str(round(t,1)) + a + \"F\")\n",
    "elif (scale == \"F\"):\n",
    "    t = (temp - 32)/1.8\n",
    "    print(\"The temperature is\", str(round(t,1)) + a + \"C\")\n",
    "else: print(\"Please provide a valid scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised ML algorithms\n",
    "Presentation of different ML classification algorithms using the iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feature and target sets:\n",
    "\n",
    "- feature_names: names of the 4 features (sepal length , sepal width, petal length, petal width)\n",
    "- features: numeric values of the 4 features\n",
    "- target_names: setosa/versicolor/virginica\n",
    "- targets: 0 (setosa), 1 (versicolor), 2(virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = data['feature_names']\n",
    "features = data['data']\n",
    "target_names = data['target_names']\n",
    "targets = data['target']\n",
    "\n",
    "print(feature_names)\n",
    "print(features[0])\n",
    "print(target_names)\n",
    "print(targets[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore target distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(targets, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data (70% train, 30% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_targets, test_targets = train_test_split(features,targets,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how the target classes are distributed within the two datasets (train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input for barplot\n",
    "unique_tr, counts_tr = np.unique(train_targets, return_counts=True)\n",
    "unique_te, counts_te = np.unique(test_targets, return_counts=True)\n",
    "\n",
    "#plot train and test data distribution\n",
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "#train data\n",
    "#subplot entries: rows, columns, index of the current plot\n",
    "plt.subplot(1,2,1)\n",
    "#barplot\n",
    "y_pos = unique_tr\n",
    "height = counts_tr\n",
    "# Create bars\n",
    "plt.bar(y_pos, height, color=['red', 'green', 'blue'])\n",
    "# Create names on the x-axis\n",
    "bars = target_names\n",
    "plt.xticks(y_pos, bars)\n",
    "plt.title('Train')\n",
    "\n",
    "#test data\n",
    "plt.subplot(1,2,2)\n",
    "#barplot\n",
    "y_pos = unique_te\n",
    "height = counts_te\n",
    "# Create bars\n",
    "plt.bar(y_pos, height, color=['red', 'green', 'blue'])\n",
    "# Create names on the x-axis\n",
    "bars = target_names\n",
    "plt.xticks(y_pos, bars)\n",
    "plt.title('Test');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratification (by targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_targets, test_targets = train_test_split(features,targets,test_size=0.3,random_state=1,stratify=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create barplot again to compare the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input for barplot\n",
    "unique_tr, counts_tr = np.unique(train_targets, return_counts=True)\n",
    "unique_te, counts_te = np.unique(test_targets, return_counts=True)\n",
    "\n",
    "#plot train and test data distribution\n",
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "#train data\n",
    "#subplot entries: rows, columns, index of the current plot\n",
    "plt.subplot(1,2,1)\n",
    "#barplot\n",
    "y_pos = unique_tr\n",
    "height = counts_tr\n",
    "# Create bars\n",
    "plt.bar(y_pos, height, color=['red', 'green', 'blue'])\n",
    "# Create names on the x-axis\n",
    "bars = target_names\n",
    "plt.xticks(y_pos, bars)\n",
    "plt.title('Train')\n",
    "\n",
    "#test data\n",
    "plt.subplot(1,2,2)\n",
    "#barplot\n",
    "y_pos = unique_te\n",
    "height = counts_te\n",
    "# Create bars\n",
    "plt.bar(y_pos, height, color=['red', 'green', 'blue'])\n",
    "# Create names on the x-axis\n",
    "bars = target_names\n",
    "plt.xticks(y_pos, bars)\n",
    "plt.title('Test');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-nearest neighbor (KNN) classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(train)\n",
    "train_s = scaler.transform(train)\n",
    "test_s = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create, fit, predict using KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = KNeighborsClassifier(n_neighbors=3)\n",
    "KNN_model.fit(train_s, train_targets)\n",
    "KNN_prediction = KNN_model.predict(test_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate accuracy of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = accuracy_score(test_targets, KNN_prediction)\n",
    "print(a)\n",
    "\n",
    "#store value\n",
    "acc_v = []\n",
    "acc_v.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How accuracy is calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(KNN_prediction==test_targets, return_counts=True)\n",
    "d = dict(zip(unique, counts)) \n",
    "d[True]/(d[False] + d[True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other classification performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(test_targets, KNN_prediction)) \n",
    "#Discuss accuracy issue when unbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore accuracy using different k values (defined in k_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_vector = []\n",
    "k_values = range(1,50,2)\n",
    "for i in k_values:\n",
    "    KNN_model = KNeighborsClassifier(n_neighbors=i)\n",
    "    KNN_model.fit(train_s, train_targets)\n",
    "    KNN_prediction = KNN_model.predict(test_s)\n",
    "    a = accuracy_score(test_targets, KNN_prediction)\n",
    "    acc_vector.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot accuracy (y-axis) as a function of k value (x-axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(range(len(k_values)), acc_vector, 'o', color =\"green\")\n",
    "plt.title(\"Accuracy comparison\")\n",
    "plt.xlabel(\"k value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "#add appropriate x-axis labels\n",
    "x1 = range(len(k_values))\n",
    "neigh = k_values\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(x1)\n",
    "ax.set_xticklabels(neigh, minor=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "Create, fit, predict, evaluate accuracy: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = tree.DecisionTreeClassifier() \n",
    "dt_classifier.fit(train, train_targets)\n",
    "pred_ct = dt_classifier.predict(test)\n",
    "a = accuracy_score(test_targets, pred_ct)\n",
    "acc_v.append(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "Create, fit, predict, evaluate accuracy: Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = ensemble.RandomForestClassifier(n_estimators=5)   # number of trees\n",
    "rf_model = rf_classifier.fit(train, train_targets)\n",
    "pred_rf = rf_model.predict(test)\n",
    "a = accuracy_score(test_targets, pred_rf)\n",
    "acc_v.append(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy comparison \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of accuracy of various methods for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(acc_v)), acc_v, 'o', color =\"green\")\n",
    "plt.title(\"Accuracy comparison\")\n",
    "plt.xlabel(\"Method\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "x1 = range(len(acc_v))\n",
    "neigh = ['KNN', 'DT', 'RF']\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(x1)\n",
    "ax.set_xticklabels(neigh, minor=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
